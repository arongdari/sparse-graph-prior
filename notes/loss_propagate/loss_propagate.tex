% !TEX TS-program = pdflatexmk
\documentclass{article} % For LaTeX2e
\usepackage{nips15submit_e,times}
\usepackage{hyperref}
\usepackage{url}
%\documentstyle[nips14submit_09,times,art10]{article} % For LaTeX 2.09

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}


\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{example}{Example}[theorem]

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\newcommand\myeq{\stackrel{\mathclap{\tiny\mbox{d}}}{=}}

\newcommand\mc{\mathcal} %calligraphic
\newcommand\ts{\mathcal} %tensor
\newcommand\mt{} %matrix
\newcommand\vt{\mathbf} %vector
\newcommand\fn{} %function
\newcommand\triple[3]{(#1 \stackrel{#2}\rightarrow #3)}
%\newcommand\triple[3]{(#1, #2, #3)}

\title{Knowledge Graph Construction with External Task}

\author{
Dongwoo Kim
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}

\maketitle

%\begin{abstract}
%\end{abstract}
\section{Notation}
We denote vectors by bold lower case letter, e.g. $\vt{a}$, matrices by bold upper case letters, e.g. $\mt{R}$, and mode-3 tensors by calligraphic upper case letters, e.g. $\ts{G} \in \mathbb{R}^{d_1 \times d_2 \times d_3}$. An index of the tensor is represented by a triple $\triple{i}{k}{j}$, and calligraphic letters are also used as a set of triples $\ts{T}$ if it is clear in the context. We use $r_{ij}$ to represent the $(i,j)$ entry of matrix $\mt{R}$ and $g_{ijk}$ to represent the $(i,j,k)$ entry of tensor $\ts{G}$. In addition, we use $\vt{r}_i$ to represent the row $i$ of matrix $\mt{R}$ and $G_k$ to represent $k$th slice of tensor $\ts{G}$.

\section{Knowledge Graph Construction with External Task}

Many active learning algorithms for knowledge graph construction only focus on obtaining as many positive triples as possible. This is not a crazy idea, however, it does not agree with a practical usage of knowledge graphs. For example, a content provider may want to use the knowledge graph to recommend items that fit to user's preference. This could be achieved by considering the similarity between different items in the knowledge graph based on a history of a user. If the active knowledge graph construction does not care the performance of following tasks, it may end up to discover some facts that do not lead any improvement in recommendation. Therefore, `good' active construction algorithms should reflect the following usages of the knowledge graph.

\subsection{General Framework}
A score function $s_\mt{X}: \mathbb{M} \rightarrow \mathbb{R}_+$.
$s_\mt{X}: \mathbb{T} \rightarrow \mathbb{R}_+$

\begin{align}
L_{\mt{X},\ts{G}} = L_\mt{X}(s_\mt{X}) + L_\ts{G}(s_\ts{G})
\end{align}
Assume that both loss function shares some parameter $\vt{v}_j$ for each entity $j$


\subsection{Co-factorisation}

A recent study \cite{Zhang2016} examines how a knowledge graph can be used for a movie recommendation. Their approach resembles a co-factorisation where two different loss functions for user-movie matrix and knowledge graph tensor are used to estimate the latent embeddings of movies and users.
Let $\vt{u}_i \in \mathbb{R}^d$ be a latent embedding of user $i$, $\vt{v}_j, \vt{v}_l \in \mathbb{R}^d$ be a latent embedding of entity $j$ and $l$, and $\mt{R}_{k} \in \mathbb{R}^{d\times d}$ be a latent embedding of relation $k$. $X \in \mc{X}^{U \times E}$, where $U$ is a number of users and $E$ is a number of entities, is a user-movie rating matrix, and $\ts{G} \in \{0,1\}^{E\times E \times K}$, where $K$ is a number of relations, is a tensor-represented knowledge graph. We use $g_{jlk}$ to denote the value of triple $t=\triple{j}{k}{l}$. The goal of co-factorisation is to minimise the following loss
\begin{align}
\label{eqn:two_losses}
L_{X, \ts{G}}(\mt{U}, \mt{V}, \ts{R}) & = L_X(\mt{U}, \mt{V}) + \lambda L_\ts{G}(\mt{V}, \ts{R})\\
& = \sum_{ij}\ell_X(x_{ij}, \vt{u}_{i}^\top \vt{v}_j) + \lambda \sum_{jlk}\ell_\ts{G}(g_{jlk}, \vt{v}_j^\top \mt{R}_{k} \vt{v}_{l}), \label{eqn:two_losses}
\end{align}
where we use standard bilinear model to score each triple given latent variables.
A squared error is typically used as a loss for the matrix factorisation. We may consider the recommendation as a binary classification problem. In this case, we can choose an appropriate loss $\ell_X$ to optimise.  We often measure the performance of these problems using AUC to take into account an imbalanced distribution of labels. In this case, it would be preferable to directly optimise AUC on a training set, or in practice, optimise a surrogate loss. However, the current objective optimise both losses for recommendation and knowledge graph construction, which may not be an optimal choice. In other words, we want to optimise the first term in RHS of Equation \ref{eqn:two_losses} instead of optimising both terms while considering the structure of a knowledge graph.
One way to achieve this goal is to design a nested objective function. One possible candidate is
\begin{align}
\label{eqn:obj}
L_{X, \ts{G}}(\mt{U}) & = \sum_{ij}\ell(x_{ij}, \vt{u}_{i}^\top \fn{f}_j(\ts{G}))
\end{align}
where feature function $\fn{f}_j : \{0,1\}^{E\times E\times K} \rightarrow \mathbb{R}^d$ extracts $d$-dimensional feature of entity $j$ from the entire knowledge graph $\ts{G}$. Two questions are naturally occurring from here: 1) How to extract feature of entity $j$ from the entire knowledge graph? 2) How does the back-propagated loss help to construct a KG? 
%Before answering these questions, let's derive the partial derivative of the objective. If we use the squared loss, the derivative w.r.t. function $\fn{f}_j$ has a form
%\begin{align}
%\frac{\partial L_{X, \ts{G}}}{\partial \fn{f}_j} = -\sum_{i}(x_{ij} - \vt{u}_i^\top \fn{f}_j) \vt{u}_i.
%\end{align}
There might be several ways to design a feature function $f$. However, instead of designing a feature function from scratch, it would be better to incorporate some ideas of existing statistical relational models since the goal of these models are highly focused on how to infer latent semantics of entities and relations. More specifically, if we can match the function $f_j$ to the latent representation of entity $j$ of some statistical model, then the Equation \ref{eqn:obj} will naturally encompass both the statistical relational model and recommendation problem.

Alternatively, we can use the co-factorisation objective in Equation \ref{eqn:two_losses}. One problem of combining two datasets in a single objective is that an optimal loss may be different across different datasets. For example, if we cast the recommendation problem as a classification problem, then it would be preferable to learn a pair-wise scorer between positive and negative data points based on the hinge loss.

%How to model feature function of an entity? The feature function $\fn{f}_j$ should reflect some local (or global) structure of the knowledge graph.  Let $\mc{T}_j$ be a set of triples that contain entity $j$. We may also use the bilinear structure to model features as follow:
%\begin{align}
%\label{eqn:feature_fn}
%\fn{f}_j(\ts{G}) = \frac{1}{|\mc{T}_j|} \bigg( \sum_{l,k:\triple{j}{k}{l} \in \mc{T}_j} \mt{R}_{k} \vt{v}_{l}/g_{jkl} + \sum_{l,k:\triple{j}{k}{l} \in \mc{T}_j}\mt{R}_{k}^\top \vt{v}_{l}/g_{lkj} \bigg).
%\end{align}
%This feature function is derived from a bilinear assumption. In the bilinear model, the ultimate goal is to infer entity vectors and relation matrices which satisfy the following equation
%\begin{align}
%g_{jkl} = \vt{v}_j ^\top \mt{R}_{k} \vt{v}_l, \quad \forall \triple{j}{k}{l}.
%\end{align}
%We have used $\vt{v}_j = g_{jkl} \mt{R}_{k} \vt{v}_l$ and let $\fn{f}_j$ be an average of these vectors across all possible triples which contain entity $j$.
%\begin{align}
%\frac{\partial \fn{f}_{jd}}{\partial\vt{v}_l} = \frac{|\mc{T}_{jl}|}{|\mc{T}_j|} \bigg( \sum \mt{R}_{k} g_{jkl} + \sum \mt{R}_{k}^\top g_{lkj} \bigg)
%\end{align}
%To compare with the second loss in Equation \ref{eqn:two_losses}, we only took the structure of knowledge graph (which entities are connected from/to entity $j$ through which relations) to model the feature function. $e$ and $R$ in Equation \ref{eqn:feature_fn} are not estimated based on some loss w.r.t. the knowledge graph.

\subsection{Active learning}
\textbf{Which triple should be queried next?} Our goal is to minimise the empirical loss in Equation \ref{eqn:obj}. Therefore, next triple $t$ should be chosen to minimise the expected loss
\begin{align}
\arg\min_t \mathbb{E}_{g_t}\bigg[\sum_{ij}\ell(x_{ij}, \vt{u}_{i}^\top  \fn{f}_j(\ts{G} \cup t))\bigg],
\end{align}
or maximise the expected gain
\begin{align}
\arg\max_t \sum_{ij}\ell(x_{ij}, \vt{u}_{i}^\top  \fn{f}_j(\ts{G})) - \mathbb{E}_{g_t}\bigg[\sum_{ij}\ell(x_{ij}, \vt{u}_{i}^\top  \fn{f}_j(\ts{G} \cup t))\bigg],
\end{align}
where we take an expectation over the possible value of triple i.e. $g_t \in \{0, 1\}$. Again, this requires some model that estimates the probability of triple such as \textsc{prescal}.

\section*{Statistical relational models}
\subsection*{RESCAL}
The original \textsc{Rescal} paper uses squared error loss to optimise the latent embeddings. Below we list some alternative losses and its derivative w.r.t. the latent variables.

\textbf{Negative log logistic loss}:
A total loss of the \textsc{Rescal} can be decomposed into a sum of individual loss
\begin{align}
L_\ts{G}(\mt{V}, \ts{R}) = \sum_{jkl} \ell_\sigma(g_{jlk}, \vt{v}_j^\top \mt{R}_{k} \vt{v}_l).
\end{align}
If the individual loss is the negative logarithm of the logistic loss, the function can be written
\begin{align}
\ell_\sigma(g_{jlk}, \vt{v}_j^\top \mt{R}_{k} \vt{v}_l) = - \bigg\{g_{jlk} \log \sigma(\vt{v}_j^\top \mt{R}_{k} \vt{v}_l) + (1- g_{jlk}) \log (1- \sigma(\vt{v}_j^\top \mt{R}_{k} \vt{v}_l))\bigg\},
\end{align}
and the derivative of the total loss w.r.t the entity vector $\vt{v}_j$ is
\begin{align}
\frac{\partial L_\ts{G}}{\partial \vt{v}_j} =  \sum_{lk}\bigg[\Big\{\sigma(\vt{v}_j^\top \mt{R}_{k} \vt{v}_l) - g_{jlk}\Big\} \mt{R}_{k} \vt{v}_l + \Big\{\sigma(\vt{v}_l^\top \mt{R}_{k_p} \vt{v}_j) - g_{ljk}\Big\} \mt{R}_{k}^\top \vt{v}_l \bigg],
\end{align}
where we consider both direction from/to entity $j$.

\textbf{Surrogate AUC loss (hinge loss)}
Let $\mc{T}^{(p)}$ be a set of positive triples and $\mc{T}^{(n)}$ be a set of negative triples.
\begin{align}
L_\ts{G}(\mt{V}, \ts{R}) = \sum_{\triple{j_p}{k_p}{l_p} \in \mc{T}^{(p)}}\sum_{\triple{j_n}{k_n}{l_n} \in \mc{T}^{(n)}} \ell_+(\vt{v}_{j_p}^\top \mt{R}_{k_p} \vt{v}_{l_p}, \vt{v}_{j_n}^\top \mt{R}_{k_n} \vt{v}_{l_n}),
\end{align}
where $\ell_+(x, y) = y - x$ if $y - x \geq 0$ else 0. Let $\mc{T}_+^{(p,n)}$ be a set of pairs of triples whose hinge loss is greater than 0. Taking the derivative of the hinge loss w.r.t. $v_j$ is
\begin{align}
\frac{\partial L_\ts{G}}{\partial \vt{v}_j} = &
- \sum_{(t_p, t_n) \in \mc{T}_+^{(p,n)} : j_p = j} \mt{R}_{k_n}\vt{v}_{l_p} - \sum_{t_p, t_n: l_p = j} \mt{R}_{k_p}^\top \vt{v}_{j_p} \\
& \quad + \sum_{t_p, t_n: j_n = j} \mt{R}_{k_n}\vt{v}_{l_n}  + \sum_{t_p, t_n: l_n = j} \mt{R}_{k_n}^\top \vt{v}_{j_n}.
\end{align}
The derivative remains the same even if we put some additional margin on the loss.

\subsection*{TranseE}
\textsc{TransE} model assumes that every entity can be represented by a linear function of relation and other entity in each triple.
\begin{align}
\vt{v}_j =  \vt{v}_l -\vt{r}_k \quad \forall \triple{j}{k}{l},
\end{align}
where both entities and relations are represented by length-$d$ vector unlike \textsc{Rescal}.
Since above equations are overdetermined system in general, the goal of \textsc{TransE} is to minimise the sum of squared distance between $\vt{v}_j$ and $\vt{v}_l -\vt{r}_k$:
\begin{align}
L_\ts{G}(\mt{V}, \mt{R}) = \sum_{\triple{j}{k}{l}}|\vt{v}_j + \vt{r}_k - \vt{v}_l|^2
\end{align}

\section{}

\begin{align}
&\mathbb{D}_{\phi}(\mt{X}, \hat{X}) + \sum_k \mathbb{D}_{\phi}(\mt{G}_k, \hat{G}_k)\\
=&\mathbb{D}_{\phi}(\mt{X}, \mt{U}\mt{V}^\top) + \sum_k \mathbb{D}_{\phi}(\mt{G}_k, \mt{V}\mt{R}_k\mt{V}^\top)\\
=& \sum_{ij} d_\phi(x_{ij}, \vt{u}_i^\top \vt{v}_j) + \sum_{\triple{j}{k}{l}} d_\phi(g_{jkl}, \vt{v}_j^\top R_k \vt{v}_l)\\
=& \sum_{ij} \phi(x_{ij}) - \phi(\vt{u}_i^\top \vt{v}_j) - \langle x_{ij}, \vt{u}_i^\top \vt{v}_j \rangle \nabla\phi(\vt{u}_i^\top \vt{v}_j) \\
&+ \sum_{\triple{j}{k}{l}} \phi(g_{jkl}) - \phi(\vt{v}_j^\top R_k \vt{v}_l) - \langle g_{jkl}, \vt{v}_j^\top R_k \vt{v}_l \rangle \nabla\phi(\vt{v}_j^\top R_k \vt{v}_l)\\
=& \sum_{ij} \phi(x_{ij}) + \phi^\star(\hat{x}_{ij}^\star) - \langle x_{ij}, \hat{x}_{ij}^\star \rangle \\
&+ \sum_{\triple{j}{k}{l}} \phi(g_{jkl}) + \phi^\star(\hat{g}_{jkl}^\star) - \langle g_{jkl}, \hat{g}_{jkl}^\star\rangle ,
\end{align}
where $\phi^\star$ is a conjugate of $\phi$, and $\hat{x}^\star = (\nabla \phi)^{-1}(\hat{x})$ is related to $\hat{x}$ by the Legendre transformation.

\section{Does the domain adaptation or transfer learning help?}
The domain adaptation often provides a systematic way to transfer knowledge from one domain to the other domain. For example, a model trained on a set of synthesised images with varying font styles is used to identify a house-number on street-view dataset with the domain adaptation \cite{Ganin2015}. In domain adaptation, each dataset comes from different source, but all datasets share the same task i.e. input distribution $p(X)$ changes between different datasets, but label distribution $p(Y|X)$ remains the same. In our case, the domain adaptation does not fit well because we tackle to solve two separate tasks: knowledge graph completion and recommendation. The transfer learning might be more appropriate in this case. The assumption behind transfer learning is that the input distribution $p(X)$ remains the same but the label distribution $p(Y|X)$ changes between different datasets, and typically, it is assumed that we have one data set that is labeled for both problems. The difference between our problem and general transfer learning problems is that the data are i.i.d. distributed in general transfer learning, but our data is not i.i.d. distributed and can be represented by multiple relations. Markov logic networks have been used to tackle the transfer learning problem in relational datasets. For example, \cite{Mihalkova2007} try to find mapping between relations from two different knowledge graphs via mapping two Markov logic networks. The MLN approach only works for homogeneous datasets does not suit in our case.


\bibliographystyle{apalike}
\bibliography{ref}

\end{document}
